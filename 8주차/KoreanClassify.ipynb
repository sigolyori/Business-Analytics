{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 64-bit ('base': conda)",
   "display_name": "Python 3.8.2 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "b80f52bb4267e73dc81b1dd7b4eace2461f9c8fb0ba47df9fdb0f854f66d641c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 한글 문서의 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "text = []\n",
    "y = []\n",
    "with open(\"movie_data.csv\", encoding=\"utf-8\") as csvfile:\n",
    "    csvreader = csv.reader(csvfile)\n",
    "    for row in csvreader:\n",
    "        #print(row)\n",
    "        if row: # 줄이 있는 것이 참인 경우에만,\n",
    "            text.append(row[0]) # 영화 리뷰를 text 리스트에 추가\n",
    "            y.append(row[2]) # 영화 이름을 text 리스트에 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Num of samples: 1827\nMovie titiles of reviews: {'코코', '신과함께', '곤지암', '인피니티 워', '라라랜드'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Num of samples: {}\".format(len(text))) # 리뷰 개수\n",
    "print(\"Movie titiles of reviews: {}\".format(set(y))) # set을 통해 제목이 한번만 출력되도록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 데이터를 training set와 test set으로 나눈다.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(text, y, random_state=0) # 비율을 지정하지 않기 때문에 75:25로 분할된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1370"
      ]
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "len(X_train) # 전체 데이터의 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt # 형태소 분석기\n",
    "twitter_tag = Okt() # 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['혹시', '나', '하고', '봤는데', '역시', '나다', ';;', '편집', '과', '사운드', '로', '주는', '작은', '공포', '영화', \"'\", '푸시', \"'\", '에서', '인상', '깊게', '봤던걸', '여기', '서', '또', '보네', ';;']\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tag.morphs(X_train[1])) # 두번째 리뷰에 대해서 형태소 단위로 tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['혹시', '역시', '편집', '사운드', '공포', '영화', '푸시', '인상', '여기', '또']"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "twitter_tag.nouns(X_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer 함수로 사용\n",
    "def twit_tokenizer(text):\n",
    "    return twitter_tag.nouns(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=2) # 최소 출현 2 이상, tokenizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train score 0.8364963503649635\nTest score 0.6717724288840262\n(1370, 1156)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=3, max_df=0.90, max_features=1000, use_idf=True, sublinear_tf=True)\n",
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, min_df=2) #Twitter 형태소분석기에서 명사만 추출하는 함수를 tokenizer로 이용\n",
    "# twit_tokenizer 대신 twitter_tag.nouns를 직접 써도 됨\n",
    "# 하나의 문서에서만 출현한 단어는 쓸모가 없으므로 제외, 즉 최소 document frequency를 2로 설정\n",
    "\n",
    "X_train_tfidf = tfidf.fit_transform(X_train) # train data 변환 -> tfidf vector\n",
    "X_test_tfidf = tfidf.transform(X_test) # test data 변환 -> tfidf vector\n",
    "\n",
    "clf = LogisticRegression() # logistic regression 분류기 선언\n",
    "clf.fit(X_train_tfidf, y_train) # 분류기 학습\n",
    "print('Train score', clf.score(X_train_tfidf, y_train)) # train data 예측정확도\n",
    "print('Test score', clf.score(X_test_tfidf, y_test)) # test data 예측정확도\n",
    "print(X_train_tfidf.shape) # 총 1156개의 명사로 이루어짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['졸잼 최고',\n",
       " '내용, 음악 , 연기력  무엇하나 빠지는것이 없네요 특히 음악은 계속 찾아 듣게되요^^',\n",
       " '아맥2D로 느즈막히 관람.... 히어로가 많이나오지만, 이걸 꽤나 잘 버무려놓음. 뻔한스토리의 틀을 벗어나려 노력한점은 높은점수를 줄만함.... 블럭버스터액션, 영상미는 말이필요없음...... 후속편 기대됨!',\n",
       " '후반부터 쫄렸다.',\n",
       " '진짜. 솔직히 한국 공포영화중에 이렇게 소재별로인건 정말 오랜만인듯; 지들끼리 소리지르고 정신없이 우왕자왕 심지어 무섭지도않어 효과음만크고 진짜최악임ㅉㅉ',\n",
       " '소문난 잔치에 먹을거 없음..ㅜㅜ',\n",
       " 'good!',\n",
       " '아 점수를 줄 수가 없네  화면은 왜그리도 흔들어 데는지........ 재미도 없고 가볍기만하고 .... 최악의 재미없는 배멀미 영화',\n",
       " '영화 보면서 펑펑물었네요~ 부모님 사랑에 대해 다시한번 생각하게 했던 영화네요^ ^',\n",
       " '슬픈 스토리지만 삶을 돌아보게 하는 영화다. 죄를 지은자는 그 벌을 고스란히 받으리라. 사회 각종범죄자들 뉘우치길 바란다.']"
      ]
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "X_test[:10] #test data에서 앞 10개를 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['인피니티 워', '라라랜드', '인피니티 워', '곤지암', '곤지암', '인피니티 워', '인피니티 워',\n",
       "       '신과함께', '코코', '신과함께'], dtype='<U6')"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "clf.predict(X_test_tfidf)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['인피니티 워', '라라랜드', '인피니티 워', '곤지암', '곤지암', '인피니티 워', '인피니티 워', '곤지암', '신과함께', '신과함께']\n"
     ]
    }
   ],
   "source": [
    "print(y_test[:10]) # test data 앞 10개의 실제 영화제목"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 성능을 개선하기 위한 노력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['혹시', '나', '하고', '봤는데', '역시', '나다', ';;', '편집', '과', '사운드', '로', '주는', '작은', '공포', '영화', \"'\", '푸시', \"'\", '에서', '인상', '깊게', '봤던걸', '여기', '서', '또', '보네', ';;']\n"
     ]
    }
   ],
   "source": [
    "# 명사 외의 다른 형태소도 많이 포함\n",
    "print(twitter_tag.morphs(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twitter_tag.morphs, min_df=2) # 명사 이외의 형태소도 사용해 봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train score 0.8963503649635036\nTest score 0.649890590809628\n(1370, 2260)\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "# 명사 사용만 한 것에 비해 Train과 Test의 편차 커짐 -> Overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[('혹시', 'Noun'), ('나', 'Josa'), ('하다', 'Verb'), ('보다', 'Verb'), ('역시', 'Noun'), ('나다', 'Verb'), (';;', 'Punctuation'), ('편집', 'Noun'), ('과', 'Josa'), ('사운드', 'Noun'), ('로', 'Josa'), ('주다', 'Verb'), ('작다', 'Adjective'), ('공포', 'Noun'), ('영화', 'Noun'), (\"'\", 'Punctuation'), ('푸시', 'Noun'), (\"'\", 'Punctuation'), ('에서', 'Josa'), ('인상', 'Noun'), ('깊다', 'Adjective'), ('보다', 'Verb'), ('여기', 'Noun'), ('서', 'Josa'), ('또', 'Noun'), ('보다', 'Verb'), (';;', 'Punctuation')]\n"
     ]
    }
   ],
   "source": [
    "print(twitter_tag.pos(X_train[1], norm=True, stem=True)) #pos()는 형태소와 품사를 함께 제공"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twit_tokenizer2(text): #전체를 다 사용하는 대신, 명사, 동사, 형용사만을 사용\n",
    "    target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in twitter_tag.pos(text, norm=True, stem=True):\n",
    "        if tag in target_tags:\n",
    "            result.append(word)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['혹시', '하다', '보다', '역시', '나다', '편집', '사운드', '주다', '작다', '공포', '영화', '푸시', '인상', '깊다', '보다', '여기', '또', '보다']\n"
     ]
    }
   ],
   "source": [
    "print(twit_tokenizer2(X_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train score 0.8715328467153285\nTest score 0.6849015317286652\n(1370, 1584)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer2, min_df=2) #명사, 동사, 형용사를 이용하여 tfidf 생성\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "\n",
    "# 가장 뛰어난 성능이라고 한다 -> 실제로 이런 모델을 만드려고 하면 어렵겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모든 형태소를 사용하며 동시에 품사도 알 수 있도록 \n",
    "\n",
    "def twit_tokenizer3(text):\n",
    "    #target_tags = ['Noun', 'Verb', 'Adjective']\n",
    "    result = []\n",
    "    for word, tag in twitter_tag.pos(text, norm=True, stem=True):\n",
    "        result.append('/'.join([word, tag])) #단어의 품사를 구분할 수 있도록 함\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train score 0.8927007299270073\nTest score 0.6739606126914661\n(1370, 2023)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer3, min_df=2)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train_tfidf, y_train)\n",
    "print('Train score', clf.score(X_train_tfidf, y_train))\n",
    "print('Test score', clf.score(X_test_tfidf, y_test))\n",
    "print(X_train_tfidf.shape)\n",
    "# Test score가 올라감"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train set score: 0.944\nTest set score: 0.676\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "ridge_clf = RidgeClassifier(alpha = 1)\n",
    "ridge_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
    "# Train score는 높게 올라감 .. Test는 별 차이 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train set score: 0.718\nTest set score: 0.643\nUsed features count: 240 out of 2023\n"
     ]
    }
   ],
   "source": [
    "#lasso를 쓰면?\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "lasso_clf.fit(X_train_tfidf, y_train)\n",
    "print('Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
    "print('Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
    "print('Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)), 'out of', X_train_tfidf.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.01102934 0.01405529 0.01144551 0.0110093  0.00918016 0.00876149\n 0.00836851 0.00795922 0.00777003 0.00737423 0.00707199 0.00665546\n 0.00659729 0.00616382 0.00588976 0.00563969 0.00546929 0.00543044\n 0.00524396 0.00523751 0.0051354  0.00507564 0.00494917 0.00478661\n 0.00466253 0.0046021  0.00455272 0.00452943 0.00432636 0.0043043\n 0.00425346 0.00416261 0.00410043 0.00401296 0.00399825 0.00396182\n 0.00392779 0.00385998 0.00373325 0.00369469 0.00365484 0.00363113\n 0.00357832 0.00354544 0.00349848 0.00346928 0.00337552 0.00334918\n 0.00332458 0.00330956 0.00323571 0.00321667 0.00315217 0.00314053\n 0.00309441 0.00307477 0.0030649  0.00301359 0.00300256 0.00296081\n 0.00293836 0.00291433 0.00288938 0.00288701 0.00286437 0.00281526\n 0.00280011 0.00276482 0.00274032 0.00271676 0.00269105 0.00266254\n 0.00264105 0.00262961 0.00260318 0.00258836 0.00257263 0.0025549\n 0.00253862 0.00252722 0.00251281 0.00248844 0.00248194 0.00245121\n 0.00244755 0.00241116 0.00239864 0.0023803  0.00236743 0.00235925\n 0.00232777 0.00231998 0.00228583 0.00225879 0.00224278 0.00222963\n 0.00222807 0.00219394 0.00218403 0.00217777 0.00216885 0.00213963\n 0.00213221 0.00211726 0.0021082  0.00208491 0.00207873 0.00206984\n 0.0020442  0.00203715 0.00203109 0.00202247 0.00200684 0.00199728\n 0.00198139 0.00197578 0.00196858 0.0019567  0.00195046 0.00193928\n 0.00192188 0.00191527 0.00190398 0.00190288 0.00189315 0.00188382\n 0.00186635 0.00185401 0.00184764 0.00184161 0.0018402  0.00182065\n 0.001813   0.00179631 0.00179194 0.00178155 0.00177619 0.00177247\n 0.00176391 0.00174575 0.00174084 0.00173493 0.00172713 0.00172038\n 0.00171324 0.00169736 0.00169107 0.00168815 0.00167718 0.00166958\n 0.0016606  0.00165005 0.00164831 0.00163445 0.00162676 0.00162542\n 0.00161713 0.00161272 0.00159771 0.00159238 0.00159037 0.00158957\n 0.00156833 0.00156387 0.00155943 0.00155314 0.00154517 0.00154178\n 0.00153878 0.00153156 0.00152027 0.00151681 0.00150908 0.00150907\n 0.00150429 0.00148962 0.00148561 0.00147865 0.00147801 0.00146682\n 0.00146001 0.00145723 0.00144468 0.00143961 0.00143002 0.00142921\n 0.0014208  0.00141638 0.00141579 0.00140818 0.0014034  0.00139324\n 0.00139056 0.00138567 0.00137493 0.00137155 0.00136727 0.00135985\n 0.00135444 0.00134977 0.00134562 0.00133558 0.00133122 0.00132535\n 0.00132194 0.00131758 0.00131066 0.00130911 0.00130505 0.00129728\n 0.00129571 0.00128405 0.00127616 0.00127324 0.00126559 0.00125941\n 0.00125722 0.00125095 0.00124375 0.00124088 0.00123686 0.00123166\n 0.00122136 0.00121416 0.00120729 0.00119822 0.00119425 0.0011902\n 0.00118219 0.00117517 0.00117452 0.0011669  0.00115835 0.00114922\n 0.00114639 0.00113962 0.00113862 0.00113157 0.00112449]\n0.6274704549280453\n[7.18722998 4.37716265 3.87707769 3.80401495 3.46987465 3.38992696\n 3.31319188 3.23081401 3.19295868 3.11176267 3.0479269  2.97464527\n 2.94181282 2.84376785 2.7792728  2.72052017 2.67818072 2.66871722\n 2.62671166 2.6211839  2.59772293 2.58190277 2.54773577 2.50549056\n 2.47514125 2.46249764 2.44458218 2.44081919 2.38195771 2.37595715\n 2.36213857 2.33646299 2.31897222 2.29462272 2.28988032 2.27951064\n 2.2696032  2.25224959 2.21275983 2.20157946 2.18941753 2.18229454\n 2.16700863 2.15629757 2.14384191 2.13417342 2.10461423 2.09580568\n 2.08809633 2.08457671 2.06118326 2.05524985 2.03983521 2.02947381\n 2.0156339  2.00808902 2.00484508 1.98892489 1.9848698  1.97080544\n 1.96433732 1.95685115 1.94851579 1.94618356 1.93878407 1.92354149\n 1.91631125 1.90417728 1.8957369  1.88786307 1.8786183  1.86911358\n 1.86110158 1.85717919 1.84914318 1.84466386 1.83680751 1.83047136\n 1.8257132  1.82052779 1.81602147 1.80661829 1.80431053 1.79331989\n 1.79183982 1.77843174 1.77363887 1.76688172 1.76225481 1.75901716\n 1.7472136  1.74547341 1.73138953 1.72112568 1.71500666 1.71000327\n 1.70948057 1.69627556 1.69249592 1.69011496 1.68727252 1.67602962\n 1.67226219 1.66647038 1.66276613 1.65396201 1.65116958 1.64756305\n 1.63885047 1.6351727  1.63216299 1.62859852 1.62272231 1.6199386\n 1.61197651 1.60973638 1.60686067 1.6019874  1.59937235 1.59485625\n 1.58767203 1.58485923 1.58104529 1.57976164 1.57568875 1.57192692\n 1.56637507 1.55945183 1.55681473 1.55449401 1.55349754 1.54521608\n 1.54228311 1.53494218 1.53323466 1.52873209 1.52685008 1.52467317\n 1.52095301 1.51360868 1.51136655 1.50844406 1.50501843 1.50295063\n 1.4990343  1.49203042 1.48921439 1.48844592 1.48323386 1.47971939\n 1.47588973 1.47125412 1.47030967 1.46441287 1.46089164 1.4600098\n 1.45645421 1.45430045 1.44757356 1.4451948  1.44418574 1.44381833\n 1.43474477 1.43241517 1.43075667 1.42734688 1.4239681  1.42213184\n 1.42056782 1.41722678 1.4129636  1.41085354 1.40692287 1.40682537\n 1.40490821 1.39769447 1.39580527 1.39275219 1.3922484  1.38695654\n 1.38382998 1.38275183 1.37645068 1.37404564 1.36964869 1.36905779\n 1.36514341 1.36291003 1.36262579 1.35901456 1.35666126 1.35220907\n 1.35071654 1.34873489 1.34301621 1.34134439 1.33943739 1.33542613\n 1.33276808 1.33056349 1.3284238  1.32349714 1.32147413 1.31838175\n 1.31677435 1.31457724 1.31126584 1.31041624 1.30838878 1.30434815\n 1.30356031 1.29770436 1.29424264 1.29220091 1.28853219 1.28520775\n 1.2841347  1.28089417 1.27725376 1.27569374 1.27362989 1.27093976\n 1.26565419 1.26203966 1.25829658 1.25355624 1.25168127 1.24946418\n 1.24542796 1.24144044 1.24113263 1.23706028 1.2325742  1.22773662\n 1.22629484 1.22251701 1.22209418 1.21818685 1.21495199]\n(239, 2023)\n"
     ]
    }
   ],
   "source": [
    "#lsa를 쓰면?\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=239, n_iter=7, random_state=42) #압축할 component의 수 지정\n",
    "svd.fit(X_train_tfidf)  \n",
    "print(svd.explained_variance_ratio_)  #계산된 각 component가 설명하는 분산의 비율\n",
    "print(svd.explained_variance_ratio_.sum())  #선택된 component들이 설명하는 분산의 합 -> 선택한 component의 수에 따라 달라짐\n",
    "print(svd.singular_values_) \n",
    "print(svd.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train set score: 0.771\nTest set score: 0.654\n"
     ]
    }
   ],
   "source": [
    "X_train_svd = svd.transform(X_train_tfidf) # 차원 축소를 통해 가장 주요한 성분 찾아 내는 것?\n",
    "X_test_svd = svd.transform(X_test_tfidf)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "SVD_clf = LogisticRegression()\n",
    "SVD_clf.fit(X_train_svd, y_train)\n",
    "print('Train set score: {:.3f}'.format(SVD_clf.score(X_train_svd, y_train)))\n",
    "print('Test set score: {:.3f}'.format(SVD_clf.score(X_test_svd, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(tokenizer = twit_tokenizer2, min_df =2).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train set Dimension: (1370, 1584)\n",
      "Test set dimension: (457, 1584)\n"
     ]
    }
   ],
   "source": [
    "X_train_cv = cv.transform(X_train) # train set을 변환\n",
    "print(\"Train set Dimension:\", X_train_cv.shape) # 몇 차원이냐\n",
    "X_test_cv = cv.transform(X_test) # test set을 변환\n",
    "print('Test set dimension:', X_test_cv.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train set score: 0.801\nTest set score: 0.685\n"
     ]
    }
   ],
   "source": [
    "# 나이브 베이즈 분류기\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "NB_clf = MultinomialNB()\n",
    "NB_clf.fit(X_train_cv, y_train)\n",
    "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train)))\n",
    "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}